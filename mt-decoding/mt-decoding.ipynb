{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890213c2",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Decoding in neural machine translation\"\n",
    "subtitle: \"Multilingual NLP -- Lab 4\"\n",
    "author: \"Philippos Triantafyllou\"\n",
    "date: last-modified\n",
    "date-format: long\n",
    "lang: en\n",
    "format:\n",
    "    pdf:\n",
    "        pdf-engine: lualatex\n",
    "        documentclass: scrartcl\n",
    "        fontsize: 16pt\n",
    "        papersize: A3\n",
    "        toccolor: blue\n",
    "        classoption: \n",
    "            - \"DIV=12\"\n",
    "            - \"parskip=relative\"\n",
    "            - \"titlepage=false\"\n",
    "        code-block-border-left: MediumBlue\n",
    "        code-block-bg: WhiteSmoke\n",
    "        template-partials:\n",
    "            - \"../_pandoc/doc-class.tex\"\n",
    "            - \"../_pandoc/toc.tex\"\n",
    "            - \"../_pandoc/before-title.tex\"\n",
    "toc: true\n",
    "toc-depth: 3\n",
    "number-depth: 1\n",
    "number-sections: true\n",
    "highlight-style: github\n",
    "fig-cap-location: top\n",
    "execute:\n",
    "  echo: true\n",
    "  output: true\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d52d58",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a845703d",
   "metadata": {},
   "source": [
    "`JoeyNMT` code, taken from the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c1b9a",
   "metadata": {},
   "source": [
    "Load model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c3b275bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from joeynmt.vocabulary import build_vocab\n",
    "from joeynmt.model import build_model\n",
    "from joeynmt.helpers import load_config, get_latest_checkpoint, load_checkpoint\n",
    "\n",
    "\n",
    "def load_model(cfg_file: str):\n",
    "\n",
    "    # Load YAML configuration\n",
    "    with tqdm(total=1, desc=\"Loading configuration\") as pbar:\n",
    "        cfg = load_config(cfg_file)\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Extract directory containing trained model checkpoints\n",
    "    model_dir = cfg[\"training\"][\"model_dir\"]\n",
    "\n",
    "    # Load source and target vocabularies defined in the data config\n",
    "    with tqdm(total=1, desc=\"Loading vocabulary\") as pbar:\n",
    "        src_vocab, trg_vocab = build_vocab(cfg[\"data\"])\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Load the latest checkpoint and initialize the model\n",
    "    with tqdm(total=1, desc=\"Loading model\") as pbar:\n",
    "        # Get the most recent checkpoint\n",
    "        check = get_latest_checkpoint(Path(model_dir))\n",
    "        model_checkpoint = load_checkpoint(check, torch.device('cpu'))  # type: ignore\n",
    "\n",
    "        # Build the model architecture using config and vocabularies\n",
    "        model = build_model(cfg[\"model\"], src_vocab=src_vocab, trg_vocab=trg_vocab)\n",
    "\n",
    "        # Restore trained parameters into the model\n",
    "        model.load_state_dict(model_checkpoint[\"model_state\"])\n",
    "        pbar.update(1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe195a",
   "metadata": {},
   "source": [
    "Greedy decoding function, used in for evaluating error propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3162e4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from torch import Tensor, IntTensor\n",
    "from torch.nn import LogSoftmax\n",
    "from joeynmt.model import Model\n",
    "\n",
    "log_softmax = LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "def greedy_decoding(model: Model, encoder_output: Tensor, max_output_length: int):\n",
    "\n",
    "    # Build a source mask marking all encoder time steps as valid\n",
    "    src_mask = torch.tensor([[[True for _ in range(encoder_output.shape[1])]]])\n",
    "\n",
    "    # Retrieve BOS and EOS token indices\n",
    "    bos_index = model.bos_index\n",
    "    eos_index = model.eos_index\n",
    "\n",
    "    # Initialize target sequence with only the BOS token and mask\n",
    "    ys = encoder_output.new_full([1, 1], bos_index, dtype=torch.long)\n",
    "    trg_mask = src_mask.new_ones([1, 1, 1])\n",
    "\n",
    "    res = []\n",
    "    for _ in range(max_output_length):\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, _, _, _ = model(\n",
    "                return_type=\"decode\",\n",
    "                trg_input=ys,\n",
    "                encoder_output=encoder_output,\n",
    "                encoder_hidden=None,\n",
    "                src_mask=src_mask,\n",
    "                unroll_steps=None,\n",
    "                decoder_hidden=None,\n",
    "                trg_mask=trg_mask\n",
    "            )\n",
    "\n",
    "            # Select logits and transform to probabilities\n",
    "            logits = logits[:, -1]\n",
    "            _ = log_softmax(logits)\n",
    "\n",
    "            # Greedily select the token with the highest score\n",
    "            _, pred_trg_token = torch.max(logits, dim=1)\n",
    "            pred_trg_token = pred_trg_token.data.unsqueeze(-1)\n",
    "\n",
    "            # Append predicted token to the target sequence prefix\n",
    "            ys = torch.cat([ys, IntTensor([[pred_trg_token]])], dim=1)\n",
    "\n",
    "            # Stop decoding if EOS token is generated\n",
    "            if pred_trg_token == eos_index:\n",
    "                break\n",
    "            # Add predicted token index to result list\n",
    "            res.append(int(pred_trg_token))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025d4a9",
   "metadata": {},
   "source": [
    "Encode source sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0cd75210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from typing import List\n",
    "from joeynmt.constants import EOS_TOKEN\n",
    "\n",
    "# Encode a tokenized source sentence into encoder hidden representations\n",
    "def encode_sentence(sentence: List[str], model):\n",
    "    \n",
    "    # Convert each source token to its vocabulary index and append EOS token\n",
    "    indexes = [model.src_vocab.lookup(token) for token in sentence + [EOS_TOKEN]]\n",
    "\n",
    "    # Create a batch of size 1 containing the indexed source sentence\n",
    "    src = torch.tensor([indexes])\n",
    "\n",
    "    # Store the true length of the source sentence for the encoder\n",
    "    lengths = torch.tensor([len(indexes)])\n",
    "    \n",
    "    # Build a source mask marking all source positions as valid\n",
    "    masks = torch.tensor([[[True for _ in range(len(indexes))]]])\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoder_output, _, _, _ = model(\n",
    "            return_type=\"encode\",\n",
    "            src=src,\n",
    "            src_length=lengths,\n",
    "            src_mask=masks\n",
    "        )\n",
    "\n",
    "    return encoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961ffc8",
   "metadata": {},
   "source": [
    "Loading configuration and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac958f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to JoeyNMT configuration file\n",
    "cfg_path = \"data/wip_model/config.yaml\"\n",
    "\n",
    "# Load configuration\n",
    "cfg = load_config(cfg_path) #type: ignore\n",
    "\n",
    "# Load trained model (CPU)\n",
    "model = load_model(cfg_path)\n",
    "\n",
    "# Read maximum output length for decoding\n",
    "max_output_length = cfg[\"testing\"][\"max_output_length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492fe572",
   "metadata": {},
   "source": [
    "Building tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joeynmt.tokenizers import build_tokenizer\n",
    "\n",
    "# Build tokenizers defined in the config\n",
    "tokenizers = build_tokenizer(cfg[\"data\"])\n",
    "\n",
    "# Select source-language tokenizer\n",
    "src_lang = cfg[\"data\"][\"src\"][\"lang\"]\n",
    "src_tokenizer = tokenizers[src_lang]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed70f24",
   "metadata": {},
   "source": [
    "Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "adfc9bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'james.']\n",
      "['my', 'name', 'is', 'james.']\n"
     ]
    }
   ],
   "source": [
    "# Raw source sentence\n",
    "s = \"My name is James.\"\n",
    "\n",
    "# Preprocess and tokenize\n",
    "s_tokenized = src_tokenizer(src_tokenizer.pre_process(s))\n",
    "\n",
    "# Inspect tokenized output\n",
    "print(s_tokenized)\n",
    "\n",
    "# Encode the tokenized sentence using the model encoder\n",
    "encoder_output = encode_sentence(s_tokenized, model)\n",
    "\n",
    "# Generate target token IDs using greedy decoding\n",
    "res = greedy_decoding(model, encoder_output, max_output_length)\n",
    "\n",
    "# Convert token IDs back to readable target tokens\n",
    "decoded_sentence = model.trg_vocab.array_to_sentence(res) # type: ignore\n",
    "\n",
    "# Print decoded output\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc48b8",
   "metadata": {},
   "source": [
    "Download data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "81c8e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/english_portuguese.tsv\", sep=\"\\t\", header=None, on_bad_lines='skip', names=[\"id1\", \"en\", \"id2\", \"pt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733476b9",
   "metadata": {},
   "source": [
    "Sort values based on longest sentences. We only use the first 50 sentences for faster execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eb7c16ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.sort_values(by=\"en\", key=lambda x: x.str.len(), ascending=False, inplace=True)\n",
    "df = df.head(50).copy()\n",
    "\n",
    "# Test that all is ok\n",
    "assert len(df) == 50\n",
    "assert df[\"en\"].notna().all()\n",
    "assert df[\"pt\"].notna().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c23d66",
   "metadata": {},
   "source": [
    "Export test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "150019fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "SRC = \"data/test_sets/test_en_50.txt\"\n",
    "REF = \"data/test_sets/test_pt_50.txt\"\n",
    "\n",
    "df[\"en\"].to_csv( SRC, index=False, header=False )\n",
    "df[\"pt\"].to_csv( REF, index=False, header=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b32955",
   "metadata": {},
   "source": [
    "Specify test files in the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5ae58e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cfg[\"data\"][\"test\"] = {\"src\": SRC, \"trg\": REF}\n",
    "cfg[\"testing\"][\"n_best\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213cc04",
   "metadata": {},
   "source": [
    "Ready to run the beam search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae100c40",
   "metadata": {},
   "source": [
    "## Impact of the beam size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ac356",
   "metadata": {},
   "source": [
    "For the beam search, we modify the config with the desired beam size and run the following:\n",
    "\n",
    "```{.bash}\n",
    "python3 -m joeynmt translate config.yaml -o output.txt --ckpt checkpoint.ckpt\n",
    "```\n",
    "\n",
    "We also specify the test set in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af664723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| eval: false\n",
    "\n",
    "import time\n",
    "import yaml\n",
    "import tempfile\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "BEAM_SIZES = [1, 5, 10, 15, 20]\n",
    "results = []\n",
    "\n",
    "CHECKPOINT_PATH = \"data/wip_model/best.ckpt\"\n",
    "INPUT_TEXT_PATH = \"data/test_sets/test_en_50.txt\"\n",
    "OUTPUT_DIRECTORY = \"data/outputs\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n",
    "\n",
    "for beam_size in BEAM_SIZES:\n",
    "    print(f\"=== Beam size {beam_size} ===\")\n",
    "\n",
    "    # update configuration in memory\n",
    "    cfg[\"testing\"][\"beam_size\"] = beam_size\n",
    "\n",
    "    output_text_path = f\"{OUTPUT_DIRECTORY}/hyp_beam{beam_size}.txt\"\n",
    "\n",
    "    # write updated config to a temporary YAML file\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".yaml\", delete=False) as temp_config_file:\n",
    "        yaml.safe_dump(cfg, temp_config_file)\n",
    "        temp_config_path = temp_config_file.name\n",
    "\n",
    "    translate_command = [\n",
    "        \"python3\",\n",
    "        \"-m\", \"joeynmt\",\n",
    "        \"translate\",\n",
    "        temp_config_path,\n",
    "        \"-o\", output_text_path,\n",
    "        \"--ckpt\", CHECKPOINT_PATH,\n",
    "    ]\n",
    "\n",
    "    start_time_seconds = time.time()\n",
    "\n",
    "    try:\n",
    "        with open(INPUT_TEXT_PATH, \"rb\") as input_file:\n",
    "            subprocess.run(\n",
    "                translate_command,\n",
    "                stdin=input_file,\n",
    "                check=True\n",
    "            )\n",
    "    finally:\n",
    "        os.remove(temp_config_path)\n",
    "\n",
    "    elapsed_time_seconds = time.time() - start_time_seconds\n",
    "    print(f\"Decoding time: {elapsed_time_seconds:.2f}s\")\n",
    "\n",
    "    results.append({\n",
    "        \"beam_size\": beam_size,\n",
    "        \"time_seconds\": elapsed_time_seconds,\n",
    "        \"output_path\": output_text_path,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e392f3",
   "metadata": {},
   "source": [
    "The time taken for each beam size is printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   beam_size  time_seconds                  output_path\n",
      "0          1     29.231966   data/outputs/hyp_beam1.txt\n",
      "1          5     73.003528   data/outputs/hyp_beam5.txt\n",
      "2         10    117.547759  data/outputs/hyp_beam10.txt\n",
      "3         15    167.287912  data/outputs/hyp_beam15.txt\n",
      "4         20    215.639901  data/outputs/hyp_beam20.txt\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba49ed7b",
   "metadata": {},
   "source": [
    "For the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8d15e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "SRC = \"data/test_sets/test_en_50.txt\"\n",
    "REF = \"data/test_sets/test_pt_50.txt\"\n",
    "HYP_DIR = \"data/outputs\"\n",
    "BEAMS = [1, 5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3cb17d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "src = open(SRC, encoding=\"utf-8\").read().splitlines()\n",
    "ref = open(REF, encoding=\"utf-8\").read().splitlines()\n",
    "refs = [ref]\n",
    "\n",
    "greedy = open(f\"{HYP_DIR}/hyp_beam1.txt\", encoding=\"utf-8\").read().splitlines()\n",
    "\n",
    "assert len(src) == len(ref) == len(greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bd9bb",
   "metadata": {},
   "source": [
    "Load `cometkiwi-da`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n",
    "comet_model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206da3af",
   "metadata": {},
   "source": [
    "For each beam size, load the hypotheses and compute BLEU, COMET, and ChrF scores against the references. To compare whether the greedy hypotheses are the same as the beam search ones, we simply compare the two strings. To actually look at \"how different\" they are, we compute the character-level Levenshtein distance.\n",
    "\n",
    "We do this in one big for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "import torch\n",
    "import Levenshtein\n",
    "\n",
    "rows = []\n",
    "most_different_examples = {}\n",
    "most_similar_examples = {}\n",
    "\n",
    "for beam in BEAMS:\n",
    "    hyp_path = f\"{HYP_DIR}/hyp_beam{beam}.txt\"\n",
    "    hyp = open(hyp_path, encoding=\"utf-8\").read().splitlines()\n",
    "    assert len(hyp) == len(src)\n",
    "\n",
    "    # BLEU / chrF\n",
    "    bleu = sacrebleu.corpus_bleu(hyp, refs).score\n",
    "    chrf = sacrebleu.corpus_chrf(hyp, refs).score\n",
    "\n",
    "    # COMET\n",
    "    comet_data = [{\"src\": s, \"mt\": h, \"ref\": r} for s, h, r in zip(src, hyp, ref)]\n",
    "    comet_out = comet_model.predict(\n",
    "        comet_data,\n",
    "        batch_size=32,\n",
    "        gpus=1 if torch.cuda.is_available() else 0,\n",
    "        num_workers=1,\n",
    "    )\n",
    "    comet = comet_out.system_score # type: ignore\n",
    "\n",
    "    # Number of hypotheses identical to greedy\n",
    "    identical_to_greedy = sum(g == h for g, h in zip(greedy, hyp))\n",
    "\n",
    "    # Character-level edit distances\n",
    "    distances = [Levenshtein.distance(g, h) for g, h in zip(greedy, hyp)]\n",
    "\n",
    "    # Top 5 most different from greedy\n",
    "    top5_diff_idx = sorted(range(len(distances)), key=lambda i: distances[i], reverse=True)[:5]\n",
    "\n",
    "    # Add most different examples\n",
    "    most_different_examples[beam] = [\n",
    "        {\n",
    "            \"index\": i,\n",
    "            \"src\": src[i],\n",
    "            \"greedy\": greedy[i],\n",
    "            \"beam\": hyp[i],\n",
    "            \"edit_distance\": distances[i],\n",
    "        }\n",
    "        for i in top5_diff_idx\n",
    "    ]\n",
    "\n",
    "    # Top 5 most similar to greedy (but not identical)\n",
    "    non_zero_diffs = [(i, d) for i, d in enumerate(distances) if d > 0]\n",
    "    non_zero_diffs.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Add most similar examples\n",
    "    most_similar_examples[beam] = [\n",
    "        {\n",
    "            \"index\": i,\n",
    "            \"src\": src[i],\n",
    "            \"greedy\": greedy[i],\n",
    "            \"beam\": hyp[i],\n",
    "            \"edit_distance\": d,\n",
    "        }\n",
    "        for i, d in non_zero_diffs[:5]\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Store aggregate results\n",
    "    rows.append({\n",
    "        \"beam\": beam,\n",
    "        \"BLEU\": bleu,\n",
    "        \"chrF\": chrf,\n",
    "        \"CometKiwi\": comet,\n",
    "        \"identical_to_greedy\": identical_to_greedy,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "70c7b729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beam</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF</th>\n",
       "      <th>CometKiwi</th>\n",
       "      <th>identical_to_greedy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.464129</td>\n",
       "      <td>21.133642</td>\n",
       "      <td>0.374681</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.021093</td>\n",
       "      <td>16.161680</td>\n",
       "      <td>0.379522</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.448007</td>\n",
       "      <td>12.478834</td>\n",
       "      <td>0.354528</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.466036</td>\n",
       "      <td>12.161700</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.500691</td>\n",
       "      <td>12.354588</td>\n",
       "      <td>0.347824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beam      BLEU       chrF  CometKiwi  identical_to_greedy\n",
       "0     1  2.464129  21.133642   0.374681                   50\n",
       "1     5  1.021093  16.161680   0.379522                    3\n",
       "2    10  0.448007  12.478834   0.354528                    3\n",
       "3    15  0.466036  12.161700   0.346429                    1\n",
       "4    20  0.500691  12.354588   0.347824                    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"beam\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdebbf4",
   "metadata": {},
   "source": [
    "It appears that increasing the beam size achieves worse results. This is a known phenomenon in the literature where increasing the beam size over 5 decreases the quality, known as the \"beam search curse\". We can see that even with a beam size of 5, BLEU and chrF scores drastically drop compared to greedy decoding.\n",
    "\n",
    "Beam search optimizes high probability sequences, but these do not necessarily correspond to better translations. Increasing the beam search size will inevitably amplify this effect. We can slightly see this effect when comparing the number of identical outputs to greedy decoding, which decreases with larger beam sizes.\n",
    "\n",
    "While BLEU and chrF scores drop, CometKiwi scores remain stable across different beam sizes (there is a slight drop still). This is likely to the fact that CometKiwi does not rely on a references, and mostly mesures fluency and adequacy of the output. A candidate translation can be fluent but have nothing to do with the reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9bd28e",
   "metadata": {},
   "source": [
    "We can look at the most different and most similar examples between greedy and beam search outputs to have a better idea of what is happening. We do not print th output as it will span many pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Beam size = 5\n",
      "================================================================================\n",
      "SRC   : \"This Inspector, when I first knew him, was a man of fourscore years, or thereabouts, and certainly one of the most wonderful specimens of winter-green that you would be likely to discover in a lifetime’s search. With his florid cheek, his compact figure, smartly arrayed in a bright-buttoned blue coat, his brisk and vigorous step, and his hale and hearty aspect, altogether he seemed—not young, indeed—but a kind of new contrivance of Mother Nature in the shape of man, whom age and infirmity had no business to touch. His voice and laugh, which perpetually re-echoed through the Custom-House, had nothing of the tremulous quaver and cackle of an old man’s utterance; they came strutting out of his lungs, like the crow of a cock, or the blast of a clarion.\"\n",
      "GREEDY: o último filme da série de anéis foi escrito por john john john e o último filme de john john john john john john john john john john john john john john john e o primeiro compositor de música de john john john john john john john john john john john john e o seu irmão mais velho de john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john\n",
      "BEAM  : \"the last film in the lord of the rings series, the return of the king debuted in mid-december and is still showing in u.s. movie theaters, the epic trilogy comes to a close with a final battle for middle earth, and frodo's heroic effort to cast the ring into the fiery lava of the fiery lav.\n",
      "Edit distance: 377\n",
      "\n",
      "SRC   : \"When we come to die, we shall be alone. From all our worldly possessions we shall be about to part. Worldly friends — the friends drawn to us by our position, our wealth, or our social qualities, — will leave us as we enter the dark valley. From those bound to us by stronger ties — our kindred, our loved ones, children, brothers, sisters, and from those not less dear to us who have been made our friends because they and we are the friends of the same Saviour, — from them also we must part. Yet not all will leave us. There is One who \"\"sticketh closer than a brother\"\" — One who having loved His own which are in the world loves them to the end.\"\n",
      "GREEDY: \"quando nós estamos a morreremos sozinho, de todos os nossos poderosos, que não são prestes a se tornar amigos - os amigos que se chamavam de nossa posição, nossa riqueza, ou de nossas qualidades sociais - deixamos que não vemos que os seus irmãos mais formarem o que os que os filhos eram tão tão tão tão tão tão tão tão tão tão tão tão tão poderosos.\n",
      "BEAM  : \"when we come to die, we shall be alone, from all our worldly possessions we shall be about to part. worldly friends — the friends drawn to us by our position, our wealth, or our social qualities, will leave us as we enter the dark valley.\n",
      "Edit distance: 261\n",
      "\n",
      "SRC   : \"Filby became pensive. “Clearly,” the Time Traveller proceeded, “any real body must have extension in four directions: it must have Length, Breadth, Thickness, and—Duration. But through a natural infirmity of the flesh, which I will explain to you in a moment, we incline to overlook this fact. There are really four dimensions, three which we call the three planes of Space, and a fourth, Time. There is, however, a tendency to draw an unreal distinction between the former three dimensions and the latter, because it happens that our consciousness moves intermittently in one direction along the latter from the beginning to the end of our lives.”\"\n",
      "GREEDY: \"filby se tornou pensivida\" \"claramente\", o viajante de tempo procedido, \"qualquer corpo real deve ter extensão em quatro direções: deve ter comprimento de breadth, espessura e duração, mas através de uma infirma natural da flesh, que eu explicará a sua própria cor.\n",
      "BEAM  : \"filby se tornou pensive.\n",
      "Edit distance: 241\n",
      "\n",
      "SRC   : \"The Americans wanted to impose the idea that a book or film should be treated like any commercial object, because they understood that alongside the army, diplomacy and trade, there is also cultural war, a battle that they intend to win both for noble reasons — the United States has always opined that its values are universal — and less noble ones: the formation of minds is the best way to sell off American products. Consider that the cinema represents the top rank of American exports, far ahead of weaponry, aeronautics or information technology! Hence their desire to impose English as a world language, even if there has been a two-decade decline in their influence.\"\n",
      "GREEDY: os americanos queriam impor a ideia de que um livro ou filme deve ser tratado como qualquer objeto comercial, porque eles entendiam que ao lado do exército, diplomacia e comércio, há também a guerra cultural, uma batalha que pretendiam ganhar tanto para as razões nobres — os estados unidos sempre opinavam que seus valores universais.\n",
      "BEAM  : \"the americans wanted to impose the idea that a book or film should be treated like any commercial object, because they understood that alongside the army, diplomacy and trade, there is also cultural war, a battle that they intend to win both for noble reasons — the united states has always opined that its values.\n",
      "Edit distance: 221\n",
      "\n",
      "SRC   : \"Mr. and Mrs. William Webster had come all the way from Woodford to Concord, leaving three babies at home, to assist their old friends at the Inaugural Ball. You must have guessed that Mollie O'Neill, as Mrs. William Webster, would have grown plumper and prettier during the busy, happy years of married life with her husband and children on their large farm. For Mollie now had a small daughter \"\"Polly,\"\" named for her beloved twin sister, and a pair of twin sons, Dan and Billy. She was more than ever in love with her husband and, many people believed, entirely under his thumb. Yet there were times when Mollie could and would assert herself in a surprising fashion just as she had in former days with her girl friends.\"\n",
      "GREEDY: ele tinha sido casado com o marido de woodford e sua filha de um marido que tinha sido filha de um marido e que ela tinha sido filha de um marido de sua mãe e de sua mãe em sua mãe em sua filha, \"garota gêmea de sua mãe e sua mãe era filha de seu marido e de sua esposa\".\n",
      "BEAM  : \"mr. and mrs. william webster had come all the way from woodford to concord, leaving three babies at home, to assist their old friends at the inaugural ball.\n",
      "Edit distance: 206\n",
      "\n",
      "================================================================================\n",
      "Beam size = 10\n",
      "================================================================================\n",
      "SRC   : \"This Inspector, when I first knew him, was a man of fourscore years, or thereabouts, and certainly one of the most wonderful specimens of winter-green that you would be likely to discover in a lifetime’s search. With his florid cheek, his compact figure, smartly arrayed in a bright-buttoned blue coat, his brisk and vigorous step, and his hale and hearty aspect, altogether he seemed—not young, indeed—but a kind of new contrivance of Mother Nature in the shape of man, whom age and infirmity had no business to touch. His voice and laugh, which perpetually re-echoed through the Custom-House, had nothing of the tremulous quaver and cackle of an old man’s utterance; they came strutting out of his lungs, like the crow of a cock, or the blast of a clarion.\"\n",
      "GREEDY: o último filme da série de anéis foi escrito por john john john e o último filme de john john john john john john john john john john john john john john john e o primeiro compositor de música de john john john john john john john john john john john john e o seu irmão mais velho de john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john\n",
      "BEAM  : \"the last film in the lord of the rings series, the return of the king debuted in mid-december and is still showing in u.s. movie theaters, the epic trilogy comes to a close with a final battle for middle earth, and frodo's heroic effort to cast the ring into the fiery lava of the fiery lav.\n",
      "Edit distance: 377\n",
      "\n",
      "SRC   : \"When we come to die, we shall be alone. From all our worldly possessions we shall be about to part. Worldly friends — the friends drawn to us by our position, our wealth, or our social qualities, — will leave us as we enter the dark valley. From those bound to us by stronger ties — our kindred, our loved ones, children, brothers, sisters, and from those not less dear to us who have been made our friends because they and we are the friends of the same Saviour, — from them also we must part. Yet not all will leave us. There is One who \"\"sticketh closer than a brother\"\" — One who having loved His own which are in the world loves them to the end.\"\n",
      "GREEDY: \"quando nós estamos a morreremos sozinho, de todos os nossos poderosos, que não são prestes a se tornar amigos - os amigos que se chamavam de nossa posição, nossa riqueza, ou de nossas qualidades sociais - deixamos que não vemos que os seus irmãos mais formarem o que os que os filhos eram tão tão tão tão tão tão tão tão tão tão tão tão tão poderosos.\n",
      "BEAM  : \"when we come to die, we shall be alone.\n",
      "Edit distance: 321\n",
      "\n",
      "SRC   : \"It is true that the passage to which we have referred, and several other passages which we could point out, are admirable when considered merely as exhibitions of mental power. We at once recognise in them that consummate master of the whole art of intellectual gladiatorship, whose speeches, imperfectly as they have been transmitted to us, should be studied day and night by every man who wishes to learn the science of logical defence. We find in several parts of the History of James the Second fine specimens of that which we conceive to have been the great characteristic Demosthenes among the Greeks, and of Fox among the orators of England, reason penetrated, and, if we may venture on the expression, made red-hot by passion.\"\n",
      "GREEDY: \"é verdadeiramente que a passagem para que nós temos referidos e várias outras passagens que nós poderemos fazer isso, são admiráveis quando considerados apenas exposições de poder mental, cuja speeches, imperfeitas, que o consumiam mestre da arte de gladiadores intelectuais, cujas speeches, imperfeitas, imperfeitas, imperfeitas, eram eram eram escritos e que eram escritos por um dia que eram escritos por sua época.\n",
      "BEAM  : \"it is true that the passage to which we have referred, and several other passages which we could point out, are admirable when considered merely as exhibitions of mental power.\n",
      "Edit distance: 318\n",
      "\n",
      "SRC   : \"One of his notable achievements came after he lobbied the government to curtail all forms of discrimination against people with disabilities. The result was a government-endorsed policy called Equalization of Opportunities for People with Disabilities. The policy promotes equal opportunity for persons with disabilities and their full participation in all social, economic, political and cultural activities. As a result, he says the policy has led to an increasing number of people with disabilities being employed in both the public and private sectors. But Chiwaula says the policy, while well meaning, needs reinforcement. This, because there are still some who are ignoring the initiative.\"\n",
      "GREEDY: uma das suas conquistas notáveis veio depois de ele pressionou o governo para curar todas as formas de discriminação contra as pessoas com desabilidades políticas que resultaram como uma política apoiada por pessoas com desabilidades econômicas, e suas relações políticas como a política de acordo com a política e a política política e a política de seus sentidos.\n",
      "BEAM  : \"one of his notable achievements came after he lobbied the government to curtail all forms of discrimination against people with disabilities.\n",
      "Edit distance: 287\n",
      "\n",
      "SRC   : \"In this regard, he says, his organization has come out with a draft bill that was sent to the Parliament three years ago. If passed, the bill will protect people with disabilities against all forms of stigmatization and discrimination. Chiwaula also helped lead a successful effort to encourage the media to avoid terms that people with disabilities find offensive, such as “disabled people” and “the blind.” They prefer “people with disabilities,” and “people with visual impairments.” His organization is running awareness campaigns encouraging primary school teachers to integrate children with disabilities in school activities.\"\n",
      "GREEDY: em que ele dizer, sua organização tem vindo com um projeto de projeto que foi enviado para o parlamento três anos atrás, o projeto vai proteger pessoas com descapacidade contra todas as formas de stigmatização e discriminação de chiwaula também ajudou a liderar um esforço bem sucedido para encorajar a mídia para evitar a mídia.\n",
      "BEAM  : in this regard, he says, his organization has come out with a draft bill that was sent to the parliament three years ago.\n",
      "Edit distance: 261\n",
      "\n",
      "================================================================================\n",
      "Beam size = 15\n",
      "================================================================================\n",
      "SRC   : \"This Inspector, when I first knew him, was a man of fourscore years, or thereabouts, and certainly one of the most wonderful specimens of winter-green that you would be likely to discover in a lifetime’s search. With his florid cheek, his compact figure, smartly arrayed in a bright-buttoned blue coat, his brisk and vigorous step, and his hale and hearty aspect, altogether he seemed—not young, indeed—but a kind of new contrivance of Mother Nature in the shape of man, whom age and infirmity had no business to touch. His voice and laugh, which perpetually re-echoed through the Custom-House, had nothing of the tremulous quaver and cackle of an old man’s utterance; they came strutting out of his lungs, like the crow of a cock, or the blast of a clarion.\"\n",
      "GREEDY: o último filme da série de anéis foi escrito por john john john e o último filme de john john john john john john john john john john john john john john john e o primeiro compositor de música de john john john john john john john john john john john john e o seu irmão mais velho de john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john\n",
      "BEAM  : \"the last film in the lord of the rings series, the return of the king debuted in mid-december and is still showing in u.s. movie theaters, the epic trilogy comes to a close with a final battle for middle earth, and frodo's heroic effort to cast the ring into the fiery lava of the fiery lav.\n",
      "Edit distance: 377\n",
      "\n",
      "SRC   : \"When we come to die, we shall be alone. From all our worldly possessions we shall be about to part. Worldly friends — the friends drawn to us by our position, our wealth, or our social qualities, — will leave us as we enter the dark valley. From those bound to us by stronger ties — our kindred, our loved ones, children, brothers, sisters, and from those not less dear to us who have been made our friends because they and we are the friends of the same Saviour, — from them also we must part. Yet not all will leave us. There is One who \"\"sticketh closer than a brother\"\" — One who having loved His own which are in the world loves them to the end.\"\n",
      "GREEDY: \"quando nós estamos a morreremos sozinho, de todos os nossos poderosos, que não são prestes a se tornar amigos - os amigos que se chamavam de nossa posição, nossa riqueza, ou de nossas qualidades sociais - deixamos que não vemos que os seus irmãos mais formarem o que os que os filhos eram tão tão tão tão tão tão tão tão tão tão tão tão tão poderosos.\n",
      "BEAM  : \"when we come to die, we shall be alone.\n",
      "Edit distance: 321\n",
      "\n",
      "SRC   : \"It is true that the passage to which we have referred, and several other passages which we could point out, are admirable when considered merely as exhibitions of mental power. We at once recognise in them that consummate master of the whole art of intellectual gladiatorship, whose speeches, imperfectly as they have been transmitted to us, should be studied day and night by every man who wishes to learn the science of logical defence. We find in several parts of the History of James the Second fine specimens of that which we conceive to have been the great characteristic Demosthenes among the Greeks, and of Fox among the orators of England, reason penetrated, and, if we may venture on the expression, made red-hot by passion.\"\n",
      "GREEDY: \"é verdadeiramente que a passagem para que nós temos referidos e várias outras passagens que nós poderemos fazer isso, são admiráveis quando considerados apenas exposições de poder mental, cuja speeches, imperfeitas, que o consumiam mestre da arte de gladiadores intelectuais, cujas speeches, imperfeitas, imperfeitas, imperfeitas, eram eram eram escritos e que eram escritos por um dia que eram escritos por sua época.\n",
      "BEAM  : \"it is true that the passage to which we have referred, and several other passages which we could point out, are admirable when considered merely as exhibitions of mental power.\n",
      "Edit distance: 318\n",
      "\n",
      "SRC   : \"One of his notable achievements came after he lobbied the government to curtail all forms of discrimination against people with disabilities. The result was a government-endorsed policy called Equalization of Opportunities for People with Disabilities. The policy promotes equal opportunity for persons with disabilities and their full participation in all social, economic, political and cultural activities. As a result, he says the policy has led to an increasing number of people with disabilities being employed in both the public and private sectors. But Chiwaula says the policy, while well meaning, needs reinforcement. This, because there are still some who are ignoring the initiative.\"\n",
      "GREEDY: uma das suas conquistas notáveis veio depois de ele pressionou o governo para curar todas as formas de discriminação contra as pessoas com desabilidades políticas que resultaram como uma política apoiada por pessoas com desabilidades econômicas, e suas relações políticas como a política de acordo com a política e a política política e a política de seus sentidos.\n",
      "BEAM  : \"one of his notable achievements came after he lobbied the government to curtail all forms of discrimination against people with disabilities.\n",
      "Edit distance: 287\n",
      "\n",
      "SRC   : \"In this regard, he says, his organization has come out with a draft bill that was sent to the Parliament three years ago. If passed, the bill will protect people with disabilities against all forms of stigmatization and discrimination. Chiwaula also helped lead a successful effort to encourage the media to avoid terms that people with disabilities find offensive, such as “disabled people” and “the blind.” They prefer “people with disabilities,” and “people with visual impairments.” His organization is running awareness campaigns encouraging primary school teachers to integrate children with disabilities in school activities.\"\n",
      "GREEDY: em que ele dizer, sua organização tem vindo com um projeto de projeto que foi enviado para o parlamento três anos atrás, o projeto vai proteger pessoas com descapacidade contra todas as formas de stigmatização e discriminação de chiwaula também ajudou a liderar um esforço bem sucedido para encorajar a mídia para evitar a mídia.\n",
      "BEAM  : in this regard, he says, his organization has come out with a draft bill that was sent to the parliament three years ago.\n",
      "Edit distance: 261\n",
      "\n",
      "================================================================================\n",
      "Beam size = 20\n",
      "================================================================================\n",
      "SRC   : \"This Inspector, when I first knew him, was a man of fourscore years, or thereabouts, and certainly one of the most wonderful specimens of winter-green that you would be likely to discover in a lifetime’s search. With his florid cheek, his compact figure, smartly arrayed in a bright-buttoned blue coat, his brisk and vigorous step, and his hale and hearty aspect, altogether he seemed—not young, indeed—but a kind of new contrivance of Mother Nature in the shape of man, whom age and infirmity had no business to touch. His voice and laugh, which perpetually re-echoed through the Custom-House, had nothing of the tremulous quaver and cackle of an old man’s utterance; they came strutting out of his lungs, like the crow of a cock, or the blast of a clarion.\"\n",
      "GREEDY: o último filme da série de anéis foi escrito por john john john e o último filme de john john john john john john john john john john john john john john john e o primeiro compositor de música de john john john john john john john john john john john john e o seu irmão mais velho de john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john john\n",
      "BEAM  : \"the last film in the lord of the rings series, the return of the king debuted in mid-december and is still showing in u.s. movie theaters, the epic trilogy comes to a close with a final battle for middle earth, and frodo's heroic effort to cast the ring into the fiery lava of the fiery lav.\n",
      "Edit distance: 377\n",
      "\n",
      "SRC   : \"It is true that the passage to which we have referred, and several other passages which we could point out, are admirable when considered merely as exhibitions of mental power. We at once recognise in them that consummate master of the whole art of intellectual gladiatorship, whose speeches, imperfectly as they have been transmitted to us, should be studied day and night by every man who wishes to learn the science of logical defence. We find in several parts of the History of James the Second fine specimens of that which we conceive to have been the great characteristic Demosthenes among the Greeks, and of Fox among the orators of England, reason penetrated, and, if we may venture on the expression, made red-hot by passion.\"\n",
      "GREEDY: \"é verdadeiramente que a passagem para que nós temos referidos e várias outras passagens que nós poderemos fazer isso, são admiráveis quando considerados apenas exposições de poder mental, cuja speeches, imperfeitas, que o consumiam mestre da arte de gladiadores intelectuais, cujas speeches, imperfeitas, imperfeitas, imperfeitas, eram eram eram escritos e que eram escritos por um dia que eram escritos por sua época.\n",
      "BEAM  : \"it is true that the passage to which we have referred, and several other passages which we could point out, are admirable when considered merely as exhibitions of mental power we at once recognise in them that consummate master of the whole art of intellectual gladiatorship, whose speeches.\n",
      "Edit distance: 291\n",
      "\n",
      "SRC   : \"One of his notable achievements came after he lobbied the government to curtail all forms of discrimination against people with disabilities. The result was a government-endorsed policy called Equalization of Opportunities for People with Disabilities. The policy promotes equal opportunity for persons with disabilities and their full participation in all social, economic, political and cultural activities. As a result, he says the policy has led to an increasing number of people with disabilities being employed in both the public and private sectors. But Chiwaula says the policy, while well meaning, needs reinforcement. This, because there are still some who are ignoring the initiative.\"\n",
      "GREEDY: uma das suas conquistas notáveis veio depois de ele pressionou o governo para curar todas as formas de discriminação contra as pessoas com desabilidades políticas que resultaram como uma política apoiada por pessoas com desabilidades econômicas, e suas relações políticas como a política de acordo com a política e a política política e a política de seus sentidos.\n",
      "BEAM  : \"one of his notable achievements came after he lobbied the government to curtail all forms of discrimination against people with disabilities.\n",
      "Edit distance: 287\n",
      "\n",
      "SRC   : \"When we come to die, we shall be alone. From all our worldly possessions we shall be about to part. Worldly friends — the friends drawn to us by our position, our wealth, or our social qualities, — will leave us as we enter the dark valley. From those bound to us by stronger ties — our kindred, our loved ones, children, brothers, sisters, and from those not less dear to us who have been made our friends because they and we are the friends of the same Saviour, — from them also we must part. Yet not all will leave us. There is One who \"\"sticketh closer than a brother\"\" — One who having loved His own which are in the world loves them to the end.\"\n",
      "GREEDY: \"quando nós estamos a morreremos sozinho, de todos os nossos poderosos, que não são prestes a se tornar amigos - os amigos que se chamavam de nossa posição, nossa riqueza, ou de nossas qualidades sociais - deixamos que não vemos que os seus irmãos mais formarem o que os que os filhos eram tão tão tão tão tão tão tão tão tão tão tão tão tão poderosos.\n",
      "BEAM  : \"when we come to die, we shall be alone, from all our worldly possessions we shall be about to part. worldly friends — the friends drawn to us by our position, our wealth, or our social qualities, will leave us as we enter the dark valley.\n",
      "Edit distance: 261\n",
      "\n",
      "SRC   : \"In this regard, he says, his organization has come out with a draft bill that was sent to the Parliament three years ago. If passed, the bill will protect people with disabilities against all forms of stigmatization and discrimination. Chiwaula also helped lead a successful effort to encourage the media to avoid terms that people with disabilities find offensive, such as “disabled people” and “the blind.” They prefer “people with disabilities,” and “people with visual impairments.” His organization is running awareness campaigns encouraging primary school teachers to integrate children with disabilities in school activities.\"\n",
      "GREEDY: em que ele dizer, sua organização tem vindo com um projeto de projeto que foi enviado para o parlamento três anos atrás, o projeto vai proteger pessoas com descapacidade contra todas as formas de stigmatização e discriminação de chiwaula também ajudou a liderar um esforço bem sucedido para encorajar a mídia para evitar a mídia.\n",
      "BEAM  : in this regard, he says, his organization has come out with a draft bill that was sent to the parliament three years ago.\n",
      "Edit distance: 261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "for beam in sorted(most_different_examples.keys()):\n",
    "    if beam == 1:\n",
    "        continue\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Beam size = {beam}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for ex in most_different_examples[beam]:\n",
    "        print(\"SRC   :\", ex[\"src\"])\n",
    "        print(\"GREEDY:\", ex[\"greedy\"])\n",
    "        print(\"BEAM  :\", ex[\"beam\"])\n",
    "        print(\"Edit distance:\", ex[\"edit_distance\"])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a5e1b",
   "metadata": {},
   "source": [
    "The examples that have the highest and lowest Levenshtein distance between greedy and beam search outputs are almost the same across different beam sizes. The worst candidate translations are not only in the source language (english), but are actually the exact source sentence copied over. Even at beam size 5, the same examples get selected, indicating that above beam size 5, the search space does not change much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b69e5",
   "metadata": {},
   "source": [
    "## Evaluating error propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2082d5",
   "metadata": {},
   "source": [
    "We basically modify the decoding function to maintain two separate prefix tensors:\n",
    "\n",
    "- `oracle_prefix` which always appends the reference token `ref_ids[t]`\n",
    "- `greedy_prefix` which appends the predicted token `pred_greedy_id`.\n",
    " \n",
    "At each position t, we run the model twice with each prefix and compare both predictions to the same reference token. We stop the loop when `pred_greedy_id` equals `eos_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "028d9813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def decoding_with_01_loss(model: Model, encoder_output: Tensor, ref_ids: list, max_output_length: int):\n",
    "    device = encoder_output.device\n",
    "    \n",
    "    # Build a source mask marking all encoder time steps as valid\n",
    "    src_mask = torch.ones(1, 1, encoder_output.shape[1], dtype=torch.bool, device=device)\n",
    "    \n",
    "    # Retrieve BOS and EOS token indices\n",
    "    bos_index = model.bos_index\n",
    "    eos_index = model.eos_index\n",
    "    \n",
    "    # Initialize both prefixes with BOS\n",
    "    oracle_prefix = torch.full([1, 1], bos_index, dtype=torch.long, device=device)\n",
    "    greedy_prefix = torch.full([1, 1], bos_index, dtype=torch.long, device=device)\n",
    "    \n",
    "    oracle_loss = 0\n",
    "    greedy_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    # Determine maximum decoding length\n",
    "    decode_length = min(len(ref_ids), max_output_length)\n",
    "    \n",
    "    for t in range(decode_length):\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 1. Predict with ORACLE prefix\n",
    "            trg_mask_oracle = torch.ones(1, 1, oracle_prefix.shape[1], dtype=torch.bool, device=device)\n",
    "            \n",
    "            # Get logits for oracle prefix\n",
    "            logits_oracle, _, _, _ = model(\n",
    "                return_type=\"decode\",\n",
    "                # Here we provide the oracle prefix\n",
    "                trg_input=oracle_prefix,\n",
    "                encoder_output=encoder_output,\n",
    "                encoder_hidden=None,\n",
    "                src_mask=src_mask,\n",
    "                unroll_steps=None,\n",
    "                decoder_hidden=None,\n",
    "                # Here we provide the oracle mask\n",
    "                trg_mask=trg_mask_oracle\n",
    "            )\n",
    "            # Get predicted token from oracle\n",
    "            _, pred_oracle = torch.max(logits_oracle[:, -1], dim=1)\n",
    "            pred_oracle_id = int(pred_oracle.item())\n",
    "            \n",
    "            # 2. Predict with GREEDY prefix\n",
    "            trg_mask_greedy = torch.ones(1, 1, greedy_prefix.shape[1], dtype=torch.bool, device=device)\n",
    "\n",
    "            # Get logits for greedy prefix\n",
    "            logits_greedy, _, _, _ = model(\n",
    "                return_type=\"decode\",\n",
    "                # Here we provide the greedy prefix\n",
    "                trg_input=greedy_prefix,\n",
    "                encoder_output=encoder_output,\n",
    "                encoder_hidden=None,\n",
    "                src_mask=src_mask,\n",
    "                unroll_steps=None,\n",
    "                decoder_hidden=None,\n",
    "                # Here we provide the greedy mask\n",
    "                trg_mask=trg_mask_greedy\n",
    "            )\n",
    "            _, pred_greedy = torch.max(logits_greedy[:, -1], dim=1)\n",
    "            pred_greedy_id = int(pred_greedy.item())\n",
    "            \n",
    "            # Count errors\n",
    "            if pred_oracle_id != ref_ids[t]:\n",
    "                oracle_loss += 1\n",
    "            if pred_greedy_id != ref_ids[t]:\n",
    "                greedy_loss += 1\n",
    "            count += 1\n",
    "            \n",
    "            # Stop if greedy predicts EOS\n",
    "            if pred_greedy_id == eos_index:\n",
    "                break\n",
    "            \n",
    "            # Update prefixes\n",
    "            oracle_prefix = torch.cat([oracle_prefix, torch.tensor([[ref_ids[t]]], device=device)], dim=1)\n",
    "            greedy_prefix = torch.cat([greedy_prefix, torch.tensor([[pred_greedy_id]], device=device)], dim=1)\n",
    "    \n",
    "    return oracle_loss, greedy_loss, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f20ef",
   "metadata": {},
   "source": [
    "Preparing the data for the experiment. We use the same test set as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13085baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your test set\n",
    "SRC_PATH = \"data/test_sets/test_en_50.txt\"\n",
    "REF_PATH = \"data/test_sets/test_pt_50.txt\"\n",
    "\n",
    "# Load raw sentences\n",
    "src_sentences = open(SRC_PATH, encoding=\"utf-8\").read().splitlines()\n",
    "ref_sentences = open(REF_PATH, encoding=\"utf-8\").read().splitlines()\n",
    "assert len(src_sentences) == len(ref_sentences)\n",
    "\n",
    "# Build  tokenizers\n",
    "tokenizers = build_tokenizer(cfg[\"data\"])\n",
    "\n",
    "# Select source and target language tokenizers\n",
    "src_lang = cfg[\"data\"][\"src\"][\"lang\"]\n",
    "trg_lang = cfg[\"data\"][\"trg\"][\"lang\"]\n",
    "\n",
    "# Get source and target tokenizers\n",
    "src_tokenizer = tokenizers[src_lang]\n",
    "trg_tokenizer = tokenizers[trg_lang]\n",
    "\n",
    "# Tokenize all sentences\n",
    "src_tokenized_sentences = [src_tokenizer(src_tokenizer.pre_process(s)) for s in src_sentences]\n",
    "ref_tokenized_sentences = [trg_tokenizer(trg_tokenizer.pre_process(s)) for s in ref_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10d92b",
   "metadata": {},
   "source": [
    "We loop over the sentences and compute the 0/1 loss for both oracle and greedy modes. Finally, we compute the average losses across all sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "66ab4f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 0/1 loss (oracle): 0.493\n",
      "Average 0/1 loss (greedy): 0.921\n"
     ]
    }
   ],
   "source": [
    "total_oracle_loss = 0\n",
    "total_greedy_loss = 0\n",
    "total_count = 0\n",
    "\n",
    "for src_tokens, ref_tokens in zip(src_tokenized_sentences, ref_tokenized_sentences):\n",
    "    # Encode source sentence\n",
    "    encoder_output = encode_sentence(src_tokens, model)\n",
    "    \n",
    "    # Convert reference tokens to IDs\n",
    "    ref_ids = [model.trg_vocab.lookup(tok) for tok in ref_tokens]\n",
    "    ref_ids.append(model.eos_index)\n",
    "    \n",
    "    # Compute 0/1 losses and accumulate\n",
    "    o_loss, g_loss, n = decoding_with_01_loss(model, encoder_output, ref_ids, max_output_length)\n",
    "    total_oracle_loss += o_loss\n",
    "    total_greedy_loss += g_loss\n",
    "    total_count += n\n",
    "\n",
    "print(\"Average 0/1 loss (oracle):\", round(total_oracle_loss / total_count, 3))\n",
    "print(\"Average 0/1 loss (greedy):\", round(total_greedy_loss / total_count, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abde878",
   "metadata": {},
   "source": [
    "The results confirm the presence of exposure bias in the NMT model.\n",
    "The oracle mode achieves a lower loss because the model was trained with teacher forcing, and is conditioned to always receive correct previous tokens.\n",
    "On the other hand we clearly see that the greedy mode decoder achieves much higher loss, because of the errors in early predictions corrupting the history and being propagated downstream.\n",
    "\n",
    "Exposure bias is a real problem and a strong limitation to maximum likelihood training with teacher forcing. To mitigate such an issue, we need to expose the model to its own predictions during training, for example using scheduled sampling or reinforcement learning techniques.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
