{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Simple reinforcement for signalling games\"\n",
        "author: \"Philippos Triantafyllou\"\n",
        "date-modified: last-modified\n",
        "date-format: long\n",
        "lang: en\n",
        "format: html\n",
        "theme: cosmo\n",
        "toc: true\n",
        "number-sections: true\n",
        "number-depth: 2\n",
        "code-line-numbers: true\n",
        "echo: true\n",
        "output: true\n",
        "cap-location: top\n",
        "embed-resources: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcWE3HO5EpVU"
      },
      "source": [
        ":::{.callout-note}\n",
        "## Instructions\n",
        "\n",
        "This notebook aims to build simple reinforcement learning for simple signalling games. The first goal is to understand how to implement and run simple reinforcement learning for basic signalling games. The second goal is to understand how to analyze and interpret the simulation.\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqSkTgfOFOh5"
      },
      "source": [
        "## Scenario\n",
        "\n",
        "The scenario is that of a two players signalling game with an environment (The Nature) that selects a state. Given the state, Alice chooses a message and when Bob receives it he selects an action. In case Bob performs the action that matches the state chosen by nature, the cooperation game is a success otherwise it is a failure.\n",
        "\n",
        "The game is characterized by:\n",
        "\n",
        " - the number of states $S$ available to Nature;\n",
        " - the number of messages $M$ available to Alice;\n",
        " - the number of actions $A$ available to Bob.\n",
        "\n",
        "States, messages and actions are represented by vectors of positive or null weights that are to be normalized before sampling. Since the weights are positive, one can normalize them straightforwardly: $$w_i = \\frac{w_i}{\\sum_{j=1}^k w_j}$$ for a vector $\\mathbf{w}$ with length $k$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple implementation of the signalling game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cej0zkmWHmyi"
      },
      "source": [
        "Implement in python a class representing this Signalling game. $S$, $M$ and $A$ should be parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SignallingGame():\n",
        "\n",
        "    def __init__(self, states: int, messages: int, actions: int, seed: int = 42):\n",
        "        self.states = states\n",
        "        self.messages = messages\n",
        "        self.message_weights = np.full((states, messages), 1e-6)\n",
        "        self.actions = actions\n",
        "        self.action_weights = np.full((states, messages), 1e-6)\n",
        "        self.rng = np.random.RandomState(seed)\n",
        "        self.stats = []\n",
        "\n",
        "    def world_state(self):\n",
        "        state =  self.rng.randint(self.states)\n",
        "        return state\n",
        "\n",
        "    def emit_message(self, state):\n",
        "        probs = self.message_weights[state, :]/np.sum(self.message_weights[state, :])\n",
        "        message = np.random.choice(self.messages, p=probs)\n",
        "        return message\n",
        "\n",
        "    def perform_action(self, message):\n",
        "        probs = self.action_weights[message, :]/np.sum(self.action_weights[message, :])\n",
        "        action = np.random.choice(self.actions, p=probs)\n",
        "        return action\n",
        "\n",
        "    def payoff(self, state, action):\n",
        "        return 1 if action == state else 0\n",
        "\n",
        "    def update_weights(self, state, message, action, payoff):\n",
        "        self.message_weights[(state, message)] += payoff \n",
        "        self.action_weights[(message, action)] += payoff\n",
        "\n",
        "    def snapshot(self, state, message, action, payoff):\n",
        "            self.stats.append({\n",
        "                \"s\": state,\n",
        "                \"m\": message,\n",
        "                \"a\": action,\n",
        "                \"p\": payoff,\n",
        "                \"mw\": self.message_weights.copy(),\n",
        "                \"aw\": self.action_weights.copy(),\n",
        "            })\n",
        "\n",
        "    def play(self, N):\n",
        "        for _ in range(N):\n",
        "            state = self.world_state()\n",
        "            message = self.emit_message(state)\n",
        "            action = self.perform_action(message)\n",
        "            payoff = self.payoff(state, action)\n",
        "            self.update_weights(state, message, action, payoff)\n",
        "            self.snapshot(state, message, action, payoff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "game = SignallingGame(3, 3, 3)\n",
        "game.play(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "print([x[\"p\"] for x in game.stats])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update weight matrices with Roth-Erev update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHMjxb1gH78m"
      },
      "source": [
        "Implement a simulation method that plays the game $N$ times and updates the player related vectors using the Roth-Erev update. For a single game the update is the following:\n",
        "\n",
        "- $w_i = \\lambda w_i + u$ if $i$ was chosen;\n",
        "- $w_i = \\lambda w_i$ if $i$ was not chosen;\n",
        "- $w_i = \\lambda w_i$ if $i$ was not sampled in this game;\n",
        "\n",
        "where $u$ is the payoff and $\\lambda \\in [0,1]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RothErevGame(SignallingGame):\n",
        "    def __init__(self, states: int, messages: int, actions: int, l: float, seed: int = 42):\n",
        "        super().__init__(states, messages, actions, seed)\n",
        "        self.l = l\n",
        "\n",
        "    def update_weights(self, state, message, action, payoff):\n",
        "        self.message_weights[state] *= self.l\n",
        "        self.message_weights[(state, message)] += payoff\n",
        "        self.action_weights[message] *= self.l\n",
        "        self.action_weights[(message, action)] += payoff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "roth_erev_game = RothErevGame(3, 3, 3, 0.5)\n",
        "roth_erev_game.play(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "print([x[\"p\"] for x in roth_erev_game.stats])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well... it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XydT93AxfJm5"
      },
      "source": [
        "Design a plotting function that displays each of your statistic typically as a function of the number of games played."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_res():\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwyHV8Offfzc"
      },
      "source": [
        "Observe the simulation. How stable is it? Which parameters are important? which parameters are less important? Consider in particular:\n",
        "\n",
        "- the initial conditions;\n",
        "- the number of games played;\n",
        "- the value of lambda;\n",
        "- the number of states;\n",
        "- the number of messages;\n",
        "- the number of actions;\n",
        "- the reward used (use a default 0/1 reward in the first place)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
