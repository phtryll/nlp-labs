{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e49c23",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Word alignment with multilingual BERT: from subwords to lexicons\"\n",
    "subtitle: \"Multilingual NLP -- Lab 2\"\n",
    "author: \"Philippos Triantafyllou\"\n",
    "date-modified: last-modified\n",
    "date-format: long\n",
    "lang: en\n",
    "format: html\n",
    "theme: cosmo\n",
    "toc: true\n",
    "number-sections: true\n",
    "number-depth: 2\n",
    "code-line-numbers: true\n",
    "echo: true\n",
    "output: true\n",
    "cap-location: top\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83b84b",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "## Instructions\n",
    "\n",
    "In this lab, we will explore how to extract a bilingual lexicon (a list of word translation pairs linking a source language to a target language) directly from the internal representations of a \"large\" multilingual language model. Specifically, we will rely on `mBERT`, a variant of `BERT` pre-trained on Wikipedia in over 100 languages (Devlin et al. 2019).\n",
    "\n",
    "As we discussed at (too) great length in class, one of the surprising findings about `mBERT` is its ability to perform cross-lingual transfer without any explicit alignment objective or parallel data (Pires, Schlinger et Garrette 2019; Wu et Dredze 2019). Although trained solely with a masked language modelling objective on monolingual corpora, `mBERT` appears to learn a shared semantic space across languages. Words that are translations of each other tend to occupy neighbouring regions in the representation space, even when the languages do not share scripts or subwords.\n",
    "\n",
    "Because of this emergent alignment, it is possible to recover word-level translation pairs by comparing the contextualised embeddings produced by `mBERT` for parallel sentences. In this lab, we will experiment with three different alignment strategies:\n",
    "\n",
    "- Direct argmax alignment, where each source word is linked to the target word with the most similar embedding.\n",
    "- Competitive linking (via the Hungarian algorithm), which enforces one-to-one alignments.\n",
    "- Canonical Correlation Analysis (CCA), which learns linear projections to better align the representation spaces of two languages (Cao, Kitaev et Klein 2020).\n",
    "\n",
    "To carry out this lab, we will rely on a range of multilingual resources. First, we require parallel corpora (collections of sentence pairs that are translations of each other) so that we can compare word representations across languages. Well-known examples include the No Language Left Behind (`NLLB`) dataset (Team et al. 2022), which provides large-scale, high-quality translations across more than 200 languages. In addition, we will use bilingual lexicons, that is, precompiled lists of word translation pairs such as those available in `MUSE` (Lample et al. 2018) or `PanLex` (Kamholz, Pool et Colowick 2014). These lexicons serve both as supervision signals (for instance when applying Canonical Correlation Analysis) and as gold standards to evaluate the accuracy of the alignments we obtain.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507e202",
   "metadata": {},
   "source": [
    "## Selecting languages\n",
    "\n",
    "We select 5 languages that are well represented in the training of `mBERT` and 5 others that are either less represented or absent (the only language that is completely absent from `mBERT` is Kurdish). All the languages also have a bilingual lexicon from `MUSE` that we will use for the CCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2c4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import disable_progress_bars\n",
    "\n",
    "disable_progress_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85593d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (language, code, link_to_MUSE)\n",
    "langs = [\n",
    "    (\"albanian\",    \"sq\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-sq.0-5000.txt\"),\n",
    "    (\"arabic\",      \"ar\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-ar.0-5000.txt\"),\n",
    "    (\"french\",      \"fr\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-fr.0-5000.txt\"),\n",
    "    (\"german\",      \"de\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-de.0-5000.txt\"),\n",
    "    (\"greek\",       \"el\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-el.0-5000.txt\"),\n",
    "    (\"hindi\",       \"hi\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-hi.0-5000.txt\"),\n",
    "    (\"japanese\",    \"ja\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-ja.0-5000.txt\"),\n",
    "    (\"macedonian\",  \"mk\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-mk.0-5000.txt\"),\n",
    "    (\"persian\",     \"fa\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-fa.0-5000.txt\"),\n",
    "    (\"thai\",        \"th\",   \"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-th.0-5000.txt\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8c7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datasets import load_dataset\n",
    "\n",
    "def install_datasets(langs):\n",
    "    corpora = {}\n",
    "\n",
    "    for lang, code, links in langs:\n",
    "        print(f\"Processing {lang}...\")\n",
    "        corpora[lang] = {}\n",
    "        \n",
    "        print(f\"\\tLoading pairs...\")\n",
    "        data = load_dataset(\n",
    "            \"sentence-transformers/parallel-sentences-jw300\",\n",
    "            f\"en-{code}\",\n",
    "            split=\"train\"\n",
    "        )\n",
    "        print(f\"\\tLoaded JW300 for {lang}\")\n",
    "        corpora[lang]['pairs'] = data.take(5000).map( # type: ignore\n",
    "            lambda x: {\n",
    "                'english': x['english'].replace('\\u200b', '').replace('\\u200f', '').replace('\\u200c', ''),\n",
    "                'non_english': x['non_english'].replace('\\u200b', '').replace('\\u200f', '').replace('\\u200c', '')\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"\\tLoading lexicons...\")\n",
    "        text = requests.get(links).content.decode(\"utf-8\", errors=\"ignore\")\n",
    "        if '\\t' in text:\n",
    "            lexicon = [tuple(line.split('\\t', 1)) for line in text.splitlines() if line.strip() and '\\t' in line]\n",
    "        else:\n",
    "            lexicon = [tuple(line.split(None, 1)) for line in text.splitlines() if line.strip()]\n",
    "        corpora[lang][\"lexicon\"] = lexicon\n",
    "\n",
    "    return corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2eda3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "def save_datasets(corpora, data_folder=\"data\"):\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "    \n",
    "    for lang, content in corpora.items():\n",
    "        lang_folder = os.path.join(data_folder, lang)\n",
    "        os.makedirs(lang_folder, exist_ok=True)\n",
    "        \n",
    "        # Save pairs as jsonl\n",
    "        pairs_path = os.path.join(lang_folder, \"pairs.jsonl\")\n",
    "        content['pairs'].to_json(pairs_path)\n",
    "        \n",
    "        # Save lexicon as text file\n",
    "        lexicon_path = os.path.join(lang_folder, \"lexicon.txt\")\n",
    "        with open(lexicon_path, 'w', encoding='utf-8') as f:\n",
    "            for src, tgt in content['lexicon']:\n",
    "                f.write(f\"{src}\\t{tgt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0552a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(langs, data_folder=\"data\"):\n",
    "    corpora = {}\n",
    "    \n",
    "    for lang, _, _ in langs:\n",
    "        lang_folder = os.path.join(data_folder, lang)\n",
    "        corpora[lang] = {}\n",
    "        \n",
    "        # Load pairs\n",
    "        pairs_path = os.path.join(lang_folder, \"pairs.jsonl\")\n",
    "        corpora[lang]['pairs'] = Dataset.from_json(pairs_path)\n",
    "        \n",
    "        # Load lexicon\n",
    "        lexicon_path = os.path.join(lang_folder, \"lexicon.txt\")\n",
    "        with open(lexicon_path, 'r', encoding='utf-8') as f:\n",
    "            lexicon = [tuple(line.strip().split('\\t', 1)) for line in f if line.strip()]\n",
    "        corpora[lang]['lexicon'] = lexicon\n",
    "    \n",
    "    return corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2d30a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing albanian...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for albanian\n",
      "\tLoading lexicons...\n",
      "Processing arabic...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for arabic\n",
      "\tLoading lexicons...\n",
      "Processing french...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for french\n",
      "\tLoading lexicons...\n",
      "Processing german...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for german\n",
      "\tLoading lexicons...\n",
      "Processing greek...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for greek\n",
      "\tLoading lexicons...\n",
      "Processing hindi...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for hindi\n",
      "\tLoading lexicons...\n",
      "Processing japanese...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for japanese\n",
      "\tLoading lexicons...\n",
      "Processing macedonian...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for macedonian\n",
      "\tLoading lexicons...\n",
      "Processing persian...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for persian\n",
      "\tLoading lexicons...\n",
      "Processing thai...\n",
      "\tLoading pairs...\n",
      "\tLoaded JW300 for thai\n",
      "\tLoading lexicons...\n"
     ]
    }
   ],
   "source": [
    "data = install_datasets(langs)\n",
    "save_datasets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f18f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_datasets(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f31d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For albanian:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['Page Two', '1945 - 1995 What Have We Learned?', '3 - 14', 'Fifty years have passed since the end of World War II.', 'In what ways has humankind progressed?'], 'non_english': ['Faqja dy', '1945 - 1995 Çfarë kemi mësuar?', '3 - 14', 'Kanë kaluar pesëdhjetë vjet që nga mbarimi i Luftës II Botërore.', 'Në cilat fusha ka bërë progres njeriu?']}\n",
      "lexicon (<class 'list'>)\n",
      "[('and', 'dhe'), ('was', 'ishte'), ('for', 'për'), ('for', 'per'), ('that', 'që')]\n",
      "\n",
      "For arabic:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['How Can I Control My TV Viewing Habits?', 'Perhaps you have asked yourself this question, as well as others: “How Can I Say No to Premarital Sex? ”', '“ How Do I Know If It’s Real Love? ”', '“ Why Do I Get So Depressed? ”', 'These are chapter titles in the new book Questions Young People Ask  — Answers That Work.'], 'non_english': ['', 'كيف يمكنني ان اضبط عادات مشاهدتي التلفزيون ؟', '', 'ربما طرحتم على أنفسكم هذا السؤال ، بالإضافة الى اسئلة اخرى مثل : « كيف يمكنني ان اقول لا للجنس قبل الزواج ؟ » ، « كيف اعرف ما اذا كان حبا حقيقيا ؟ » ، و « لماذا أكتئب الى هذا الحد ؟ » .', 'ان هذه الاسئلة هي عناوين بعض الفصول من كتاب اسئلة يطرحها الاحداث — اجوبة تنجح .']}\n",
      "lexicon (<class 'list'>)\n",
      "[('the', 'the'), ('the', 'ال'), ('and', 'وال'), ('was', 'كانت'), ('was', 'كان')]\n",
      "\n",
      "For french:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['“ A Good Word for the Witnesses ”', 'THE preaching activity of Jehovah’s witnesses is growing very rapidly.', 'This has required a large expansion of facilities at their international headquarters in Brooklyn, New York.', 'The expansion is arousing much comment in the community, even prompting a sermon at the Plymouth Church (Congregational), located just two blocks away.', 'More than a century ago, the church’s first minister, Henry Ward Beecher, lived on property that is now part of the Watchtower Society’s headquarters complex.'], 'non_english': ['“ Éloge des Témoins ”', 'L’ŒUVRE de prédication des témoins de Jéhovah s’étend rapidement.', 'Cette extension a exigé l’agrandissement de leur siège principal situé à Brooklyn, New York.', 'Pareille expansion suscite de nombreux commentaires dans la localité et a même été l’objet d’un prêche prononcé dans le temple Plymouth (de l’Église congrégationaliste), situé à deux pâtés de maisons du siège des témoins de Jéhovah.', 'Il y a plus d’un siècle, le premier pasteur de ce temple, Henry Ward Beecher, habitait une maison qui fait partie aujourd’hui de l’ensemble des bâtiments appartenant à la Société Watchtower.']}\n",
      "lexicon (<class 'list'>)\n",
      "[('the', 'le'), ('the', 'les'), ('the', 'la'), ('and', 'et'), ('was', 'fut')]\n",
      "\n",
      "For german:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['“ A Good Word for the Witnesses ”', 'THE preaching activity of Jehovah’s witnesses is growing very rapidly.', 'This has required a large expansion of facilities at their international headquarters in Brooklyn, New York.', 'The expansion is arousing much comment in the community, even prompting a sermon at the Plymouth Church (Congregational), located just two blocks away.', 'More than a century ago, the church’s first minister, Henry Ward Beecher, lived on property that is now part of the Watchtower Society’s headquarters complex.'], 'non_english': ['„ Ein Wort zugunsten der Zeugen Jehovas “', 'DAS Predigtwerk der Zeugen Jehovas dehnt sich sehr schnell aus.', 'Deshalb mußte ihr Hauptsitz in Brooklyn, New York (USA), vergrößert werden.', 'Diese Vergrößerung bildet einen Gesprächsstoff in Brooklyn; in der Plymouth - Kirche (Kongregationalisten), zwei Häuserblocks vom Hauptsitz entfernt, wurde sogar eine Predigt über dieses Thema gehalten.', 'Vor mehr als hundert Jahren wohnte der erste Pfarrer dieser Kirche, Henry Ward Beecher, in einem Haus, das auf Boden gebaut war, der jetzt zu dem Grund gehört, auf dem die Gebäude des Hauptsitzes der Watchtower Society stehen.']}\n",
      "lexicon (<class 'list'>)\n",
      "[('the', 'die'), ('the', 'der'), ('the', 'dem'), ('the', 'den'), ('the', 'das')]\n",
      "\n",
      "For greek:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['“ A Good Word for the Witnesses ”', 'THE preaching activity of Jehovah’s witnesses is growing very rapidly.', 'This has required a large expansion of facilities at their international headquarters in Brooklyn, New York.', 'The expansion is arousing much comment in the community, even prompting a sermon at the Plymouth Church (Congregational), located just two blocks away.', 'More than a century ago, the church’s first minister, Henry Ward Beecher, lived on property that is now part of the Watchtower Society’s headquarters complex.'], 'non_english': ['« Ένας Καλός Λόγος για τους Μάρτυρας »', 'Η ΔΡΑΣΙΣ κηρύγματος των μαρτύρων του Ιεχωβά μεγαλώνει πολύ γρήγορα.', 'Αυτό χρειάσθηκε μια μεγάλη επέκτασι ευκολιών στα διεθνή των γραφεία στο Μπρούκλυν της Νέας Υόρκης.', 'Η επέκτασις εγείρει πολλά σχόλια στην κοινότητα, και προκάλεσε ακόμη την εκφώνησι μιας ομιλίας στην Κογκρεγκασιοναλιστική Εκκλησία του Πλύμουθ, που κείται δύο μόνον τετράγωνα μακρυά.', 'Πριν από εκατό χρόνια και πλέον, ο πρώτος λειτουργός της εκκλησίας αυτής, ο Χένρυ Ουώρντ Μπήτσερ, διέμενε σε ιδιοκτησία που τώρα αποτελεί μέρος του συμπλέγματος των γραφείων της Εταιρίας Σκοπιά.']}\n",
      "lexicon (<class 'list'>)\n",
      "[('the', 'το'), ('and', 'και'), ('was', 'ήταν'), ('for', 'για'), ('for', 'for')]\n",
      "\n",
      "For hindi:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['Big Business and Crime', 'BIG BUSINESS!', 'It affects all of us. It helps us  — and it harms us.', 'And there are things we can do about it. A giant, or “big, ” corporation may have assets worth $1,500,000,000.', 'Many have far more. That kind of money represents power.'], 'non_english': ['बड़ा व्यवसाय और अपराध', 'बड़ा व्यवसाय!', 'हम सब पर इसका प्रभाव पड़ता है ।', 'यह हमारी सहायता करता है — और हमें हानि भी पहुँचाता है ।', 'और कुछ ऐसी बातें हैं जो हम उसके बारे में कर सकते हैं ।']}\n",
      "lexicon (<class 'list'>)\n",
      "[('and', 'और'), ('was', 'था'), ('was', 'थी'), ('for', 'लिये'), ('that', 'उस')]\n",
      "\n",
      "For japanese:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['“ A Good Word for the Witnesses ”', 'THE preaching activity of Jehovah’s witnesses is growing very rapidly.', 'This has required a large expansion of facilities at their international headquarters in Brooklyn, New York.', '', 'The expansion is arousing much comment in the community, even prompting a sermon at the Plymouth Church (Congregational), located just two blocks away.'], 'non_english': ['「エホバ  の  証人  へ  の  賛辞」', 'エホバ  の  証人  の  伝道  活動  は  急速  に  発展  し  た  ため ， ニューヨーク  市  ブルックリン  に  ある  その  国際  本部  の  施設  は  大いに  拡張  さ  れ  まし  た。', 'この  こと  は  その  付近  の  人々  の  話題  に  も  のぼり ， 本部  から  2  区画  先  の  プリマス  教会 （ 組合  教会 ） では ， 説教  の  中  に  さえ  取り上げ  られ  まし  た。', '100  年  ほど  前 ， その  教会  の  初代  の  牧師  だっ  た  ヘンリー  ･  ウォード  ･  ビーチャー  の  住ん  で  い  た  建物  は  今  で  は ， ものみの塔  協会  の  大  規模  な  本部  の  建物  の  一部  と  なっ  て  い  ます。', 'さて ， 「エホバ  の  証人  へ  の  賛辞」と  題する  その  説教  を  し  た  ハリー  ･  H  ･  クルーナー  博士  は ， まず  最初  に  こう  述べ  まし  た。「']}\n",
      "lexicon (<class 'list'>)\n",
      "[('and', 'そして'), ('was', 'was'), ('for', 'for'), ('from', 'から'), ('this', 'この')]\n",
      "\n",
      "For macedonian:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['Young People Ask...', 'How Can I Cope With Injustice?', '“ Only those who have money are respected, but we who don’t even have anything to eat or anywhere to sleep are treated like animals.', 'If I expect anything for the future, it is to die without anyone taking notice. ” — Arnulfo, a 15 - year - old homeless boy.', 'THERE is much injustice in the world.'], 'non_english': ['Младите прашуваат...', 'Како можам да се справам со неправдата?', '„ Ги почитуваат само оние што имаат пари, додека нас кои немаме дури ни што да јадеме ниту каде да спиеме, нѐ третираат како животни.', 'Ако очекувам нешто во иднината, тоа е да умрам и никој да не го забележи тоа “(Арнулфо, 15 - годишно бездомно момче).', 'ВО СВЕТОТ има многу неправди.']}\n",
      "lexicon (<class 'list'>)\n",
      "[('the', 'на'), ('was', 'била'), ('was', 'беше'), ('for', 'за'), ('that', 'тоа')]\n",
      "\n",
      "For persian:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['© 2016 Watch Tower Bible and Tract Society of Pennsylvania', 'This publication is not for sale. It is provided as part of a worldwide Bible educational work supported by voluntary donations.', 'To make a donation, please visit www.jw.org.', '', 'Unless otherwise indicated, Scripture quotations are from the modern - language New World Translation of the Holy Scriptures.'], 'non_english': ['© 2016 International Bible Students Association', 'این نشریه برای فروش نیست و جهت آموزش جهانی کتاب مقدّس تهیه شده است و مخارج آن از طریق اعانات تأمین میگردد .', 'برای اهدای اعانه میتوانید به وبسایت www.jw.org / fa مراجعه نمایید .', 'در نقل آیات بخش عبری کتاب مقدّس ، از ترجمهٔ هزارهٔ نو ۲۰۱۴ و بخش یونانی ، از کتاب مقدّس — ترجمهٔ دنیای جدید — مَتّی تا مکاشفه استفاده شده است .', 'در غیر این صورت نام ترجمهٔ مورد نظر ذکر شده است .']}\n",
      "lexicon (<class 'list'>)\n",
      "[('the', 'را'), ('was', 'بود'), ('for', 'برای'), ('that', 'که'), ('with', 'با')]\n",
      "\n",
      "For thai:\n",
      "pairs (<class 'datasets.arrow_dataset.Dataset'>)\n",
      "{'english': ['', 'Religion’s Future in View of Its Past', 'Part 13  — 476 C.E. onward  — Out of Darkness, Something “Holy ”', '“ Sins committed in the dark are seen in Heaven like sheets of fire. ”  — Chinese proverb', 'IN APRIL 1988 the Church in the Soviet Union rejoiced to hear General Secretary Mikhail Gorbachev publicly state that mistakes made by the State in its relationship with the Church and its members were to be corrected.'], 'non_english': ['อนาคต  ของ  ศาสนา  จาก  การ  พิจารณา  ศาสนา  ใน  อดีต', 'ตอน  ที่ 13: จาก ส.', 'ศ. 476 เป็น  ต้น  มา — สิ่ง  ที่  ถือ  ว่า “ศักดิ์สิทธิ์ ” จาก  ความ  มืด', '“ บาป  ซึ่ง  ได้  กระทำ  ใน  ที่  มืด  ปรากฏ  ดุจ  เปลว  เพลิง  ใน  สวรรค์. ” — สุภาษิต  จีน', 'เดือน  เมษายน 1988 คริสต์  จักร  ใน  สหภาพ  โซเวียต  พา  กัน  ชื่นชม  ที่  ได้  ยิน  เลขาธิการ  ใหญ่  มิ คา อิล กอร์ บา ชอฟ  แถลง  อย่าง  เปิด  เผย  ว่า  ข้อ  ผิด  พลาด  ต่าง ๆ ใน  ความ  สัมพันธ์  ที่  รัฐ  ได้  กระทำ  ต่อ  คริสต์  ศาสนจักร  และ  คริสต์  สมาชิก  จะ  ต้อง  ได้  รับ  การ  แก้ไข.']}\n",
      "lexicon (<class 'list'>)\n",
      "[('the', 'เดอะ'), ('and', 'และ'), ('and', 'แล้ว'), ('for', 'สำหรับ'), ('for', 'เพื่อ')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang, corpora in data.items():\n",
    "    print(f\"For {lang}:\")\n",
    "    for keys, vals in corpora.items():\n",
    "        print(f\"{keys} ({type(vals)})\")\n",
    "        print(f\"{vals[:5]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a272702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8190a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc73612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"google-bert/bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06df3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"Replace me by any text you'd like.\", \"Another text to encode.\"]\n",
    "encoded_input = tokenizer(text, return_tensors='pt', padding=True)\n",
    "outputs = model(\n",
    "    **encoded_input,\n",
    "    output_hidden_states=True,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e32210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "tensor([  101, 72337, 72654, 10911, 10155, 11178, 15541, 13028,   112,   172,\n",
      "        11850,   119,   102])\n",
      "13\n",
      "tensor([  101, 17101, 15541, 10114, 10110, 54261,   119,   102,     0,     0,\n",
      "            0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "for input in encoded_input['input_ids']:\n",
    "    print(len(input))\n",
    "    print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "963f8e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, None]\n"
     ]
    }
   ],
   "source": [
    "word_ids = encoded_input.word_ids(batch_index=0)\n",
    "print(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf766a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13, 768])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = outputs.hidden_states[-1]\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1a5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
